{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning By Building Speech Emotions Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello friends, thank you for taking part in the internal training session that I organized. I hope you enjoy it. To hone and deepen your knowledge about the material that I have presented, you can try to do LBB below.There are 2 research datasets commonly used for speech emotion recognition.\n",
    "\n",
    "1. [Crowd-sourced Emotional Mutimodal Actors Dataset(CREMA-D)](https://github.com/CheyneyComputerScience/CREMA-D)\n",
    "2. [Toronto Emotional Speech Set Data(TESS)](https://tspace.library.utoronto.ca/handle/1807/24487)\n",
    "3. If you feel challenged, the CNN model we have created previously has an overfit where this condition is not good enough. Try to improve the model so that it produces good accuracy and does not overfit or underfit.\n",
    "\n",
    "Based on what we have learned previously (how we read data, extract sound features, create classification models) please choose one of the datasets above and try to do speech emotion recognition by building a machine learning model that is good enough to predict each emotion. You can use whatever machine learning algorithm you know to do this task. Feel free to ask me if you are having a hard time working on it. Thank you and see you at the other internal training which was more exciting than we have done :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyaudio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fea9d252a229>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwave\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mCHUNK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1024\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mFORMAT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpaInt16\u001b[0m \u001b[1;31m#paInt8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyaudio'"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "CHUNK = 1024 \n",
    "FORMAT = pyaudio.paInt16 #paInt8\n",
    "CHANNELS = 2 \n",
    "RATE = 44100 #sample rate\n",
    "RECORD_SECONDS = 4\n",
    "WAVE_OUTPUT_FILENAME = \"output10.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK) #buffer\n",
    "\n",
    "print(\"* recording\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data) # 2 bytes(16 bits) per channel\n",
    "\n",
    "print(\"* done recording\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow_GPU",
   "language": "python",
   "name": "tensorflow_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
